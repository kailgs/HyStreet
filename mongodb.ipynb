{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92933d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdff4415",
   "metadata": {},
   "source": [
    "# Daten einlesen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa8074c",
   "metadata": {},
   "source": [
    "Da alle csv-Dateien im Ordner 'data' enthalten sind, können wir mit dem Befehl ```os.listdir(PATH)``` alle Dateinamen auflisten und in der Variable *files* speichern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b7a547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/bremen-obernstraße-20190930-20221031-hour.csv',\n",
       " 'data/dresden-prager straße (nord)-20190728-20221031-hour.csv',\n",
       " 'data/düsseldorf-königsallee ostseite (süd)-20180430-20221031-hour.csv',\n",
       " 'data/frankfurt a.m.-zeil (mitte)-20190630-20221031-hour.csv',\n",
       " 'data/hamburg-jungfernstieg-20180927-20221031-hour.csv',\n",
       " 'data/hannover-georgstraße-20180731-20221031-hour.csv',\n",
       " 'data/mainz-stadthausstraße-20180430-20221031-hour.csv',\n",
       " 'data/münchen-kaufingerstraße-20190827-20221031-hour.csv',\n",
       " 'data/rostock-kröpeliner straße (west)-20191031-20221031-hour.csv',\n",
       " 'data/saarbrücken-bahnhofstraße (mitte)-20180430-20221031-hour.csv',\n",
       " 'data/stuttgart-königstraße (mitte)-20180430-20221031-hour.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [ 'data/' + x for x in os.listdir('data') ]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74418739",
   "metadata": {},
   "source": [
    "# Daten aufbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83339e2e",
   "metadata": {},
   "source": [
    "Zwar jliegen uns die Daten bereits im csv Format vor und können somit theoretisch direkt verwendet werden, für spätere Auswertungen ist es dennoch sinnvoll einige der Spalten, die aus zusammengesetzten Informationen bestehen, in ihre atomaren Bestandteile aufzuteilen und diese einzeln zu speichern.\n",
    "\n",
    "Um die Transformation der Daten durchzuführen, wird das Package *Pandas* verwendet. Wir startet mit dem Einlesen der csv Dateien in einzelne Panda-Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e5d0bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>time of measurement</th>\n",
       "      <th>weekday</th>\n",
       "      <th>pedestrians count</th>\n",
       "      <th>temperature in ºc</th>\n",
       "      <th>weather condition</th>\n",
       "      <th>incidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obernstraße, Bremen</td>\n",
       "      <td>2019-10-01 00:00:00 +0200</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Obernstraße, Bremen</td>\n",
       "      <td>2019-10-01 01:00:00 +0200</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Obernstraße, Bremen</td>\n",
       "      <td>2019-10-01 02:00:00 +0200</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Obernstraße, Bremen</td>\n",
       "      <td>2019-10-01 03:00:00 +0200</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Obernstraße, Bremen</td>\n",
       "      <td>2019-10-01 04:00:00 +0200</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              location        time of measurement  weekday  pedestrians count  \\\n",
       "0  Obernstraße, Bremen  2019-10-01 00:00:00 +0200  Tuesday                 16   \n",
       "1  Obernstraße, Bremen  2019-10-01 01:00:00 +0200  Tuesday                  7   \n",
       "2  Obernstraße, Bremen  2019-10-01 02:00:00 +0200  Tuesday                  6   \n",
       "3  Obernstraße, Bremen  2019-10-01 03:00:00 +0200  Tuesday                  5   \n",
       "4  Obernstraße, Bremen  2019-10-01 04:00:00 +0200  Tuesday                  4   \n",
       "\n",
       "   temperature in ºc weather condition incidents  \n",
       "0                NaN               NaN       NaN  \n",
       "1                NaN               NaN       NaN  \n",
       "2                NaN               NaN       NaN  \n",
       "3                NaN               NaN       NaN  \n",
       "4                NaN               NaN       NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [ pd.read_csv(x, delimiter=';') for x in files ] # Stadt1 in data[0], Stadt2 in data[1] ...\n",
    "data[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1842733a",
   "metadata": {},
   "source": [
    "Aufgespaltet werden demnach also die beiden Spalten **location** und **time of measurement**.\n",
    "\n",
    "Die Daten der Spalte **location** bestehen jeweils immer aus zwei Informationen: Dem Ort der Messung und die dazugehörige Stadt. Separiert werden diese durch ein Komma. Da unabhängig vom Namen des Ortes oder Stadt in den Zellen jeweils immer nur ein Komma zu finden ist, können wir die von Pandas zur Verfügung gestellte Funktion ```DATAFRAME.str.split()``` verwenden, die die Werte anhand eines gegeben Strings separiert und daraus neue Spalten erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4490861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateLocation(data):\n",
    "    '''Separate location into [address, location, city]'''\n",
    "    for i in range(len(data)):\n",
    "        data[i].rename(columns={'location' : 'address'})\n",
    "        data[i][['location', 'city']] = data[i]['address'].str.split(\",\", expand=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9dc09d",
   "metadata": {},
   "source": [
    "Die zweite zu separierende Information liegt in der Spalte **time of measurement**. Hier enthalten sind sowohl nützliche, als auch für uns nicht weiter wichtige Informationen.\n",
    "\n",
    "Die Spalte selbst besteht wiederum aus drei Informationen: Dem Datum, der Uhrzeit und der Zeitzone, auf welche die Zeitangabe bezogen ist. Diese Daten sind mit Leerzeichen separiert, wir gehen also ähnlich wie mit der Spalte **location** vor und spalten die Information in ihre Bestandteile auf. Um leichter mit den Datums- und Zeitangaben arbeiten zu können, spalten wir diese ebenso auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85799939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateTime(data):\n",
    "    '''Separate time of measurement into [year, month, day, hour, minute, second, timezone]'''\n",
    "    for i in range(len(data)):\n",
    "        data[i][['date','time', 'timezone']]= data[i][\"time of measurement\"].str.split(\" \",expand=True)\n",
    "        data[i][['year', 'month', 'day']] = data[i]['date'].str.split(\"-\", expand=True)\n",
    "        data[i][['hour', 'minute', 'second']] = data[i]['time'].str.split(\":\", expand=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae1dce4",
   "metadata": {},
   "source": [
    "Da wir nur Städte in Deutschland betrachten, ist die Information in welcher Zeitzone die Messung durchgeführt wurde nicht weiter relevant und kann somit entfernt werden. Ebenso interessiert uns die Minute und Sekunde der Messung nicht, da immer nur zur vollen Stunde gemessen wurde. Wir entfernen also für uns nicht weiter relevante Spalte und bennenen zusätzlich diverse Spalten für eine bessere Lesbarkeit um. Schließen werden noch die Datentypen der Spalten angepasst, um leichter mit ihnen arbeiten zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b9ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(data):\n",
    "    '''Rename columns, drop unneccessary columns and adjust data types'''\n",
    "    for i in range(len(data)):\n",
    "        data[i] = data[i].rename(columns={\"pedestrians count\" : \"pedestrians\", \"temperature in ºc\" : \"temperature\", \"weather condition\" : \"weatherCondition\"})\n",
    "        data[i].drop(columns=['time of measurement', 'date', 'time', 'timezone', 'minute', 'second'], inplace=True)\n",
    "        data[i] = data[i].astype({'year' : 'int16', 'month' : 'int16', 'day' : 'int16', 'hour' : 'int16', 'incidents' : 'int16', 'temperature' : 'int16', 'pedestrians' : 'int32'}, errors='ignore')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98c1917",
   "metadata": {},
   "source": [
    "Da wir uns nur auf die Daten im Zeitraum von 2020 - 2022 beschränken wollen, werden schließlich noch alle Daten, die nicht in diesem Zeitraum liegen entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fa2097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterData(data):\n",
    "    '''Delete all rows where the year is not between 2020 and 2022'''\n",
    "    for i in range(len(data)):\n",
    "        data[i].drop(data[i][(data[i].year < 2020) | (data[i].year > 2022)].index, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270eee1c",
   "metadata": {},
   "source": [
    "Zuletzt wenden wir alle Funktionen auf unseren Datensatz an und erhalten die angepassten Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5354bef",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'address'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\Programme\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'address'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16144/1284884354.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseparateLocation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseparateTime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleanData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilterData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16144/2394437085.py\u001b[0m in \u001b[0;36mseparateLocation\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'location'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m'address'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'location'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'city'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'address'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'address'"
     ]
    }
   ],
   "source": [
    "data = separateLocation(data)\n",
    "data = separateTime(data)\n",
    "data = cleanData(data)\n",
    "data = filterData(data)\n",
    "\n",
    "data[0].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b22e8c",
   "metadata": {},
   "source": [
    "# Daten in MongoDB speichern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a1bc9d",
   "metadata": {},
   "source": [
    "Um die verarbeiteten Daten schließlich dauerhaft zu speichern, lesen wir sie in ein MongoDB ein. Dafür wird das Package *pymongo* verwendet.\n",
    "\n",
    "Zunächst muss der MongoDB Service gestartet werden, anschließend kann mit der Ausführung des Notebooks fortgeführt werden. Wir startet damit uns mit dem Service zu verbinden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a84ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient('mongodb://localhost:27017')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0974446c",
   "metadata": {},
   "source": [
    "MongoDB ist ein nicht relationale Datenbank, die ihre Daten im JSON-Format hält. Pandas stellt hierfür die Funktion ```DATAFRAME.to_dict()``` zur Verfügung, mit welcher wir unsere Dataframes in ein JSON-Objekt konvertieren können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a0a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataJson = dict()\n",
    "for i in range(len(data)):\n",
    "    data[i] = data[i].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bda3db6",
   "metadata": {},
   "source": [
    "Nun muss auf die Datenbank zugegriffen werden. Falls diese noch nicht vorhanden ist, wird sie automatisch erstellt. Wir speichern anschließend alle Daten in der Collection **HyStreetData**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01dabcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client['HyStreet']\n",
    "\n",
    "for i in range(len(data)):\n",
    "    db.HyStreetData.insert_many(data[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
